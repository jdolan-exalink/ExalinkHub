
version: '3.8'
services:
  lpr-backend:
    build:
      context: ./backend/lpr
      dockerfile: Dockerfile
    image: exalink/lpr-backend:latest
    container_name: exalink-lpr-backend
    restart: unless-stopped
    ports:
      - "${LPR_PORT:-2221}:2221"
    environment:
      - LPR_HOST=0.0.0.0
    networks:
      - lpr-network
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.lpr.rule=Host(`lpr.local`)"
      - "traefik.http.services.lpr.loadbalancer.server.port=2221"
      - "com.exalink.service=lpr-backend"
      - "com.exalink.version=1.0.0"

  lpr-redis:
    image: redis:7-alpine
    container_name: exalink-lpr-redis
    restart: unless-stopped
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD:-exalink123}
    volumes:
      - lpr-redis-data:/data
    networks:
      - lpr-network
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    labels:
      - "com.exalink.service=lpr-redis"

  lpr-proxy:
    image: nginx:alpine
    container_name: exalink-lpr-proxy
    restart: unless-stopped
    ports:
      - "${LPR_HTTPS_PORT:-2443}:443"
      - "${LPR_HTTP_PORT:-2280}:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    networks:
      - lpr-network
      - public
    depends_on:
      - lpr-backend
    profiles:
      - proxy
    labels:
      - "com.exalink.service=lpr-proxy"

  lpr-monitor:
    image: prom/node-exporter:latest
    container_name: exalink-lpr-monitor
    restart: unless-stopped
    command:
      - '--path.rootfs=/host'
    volumes:
      - '/:/host:ro,rslave'
    networks:
      - lpr-network
    profiles:
      - monitoring
    labels:
      - "com.exalink.service=lpr-monitor"

  conteo-backend:
    build:
      context: ./backend/conteo
      dockerfile: Dockerfile
    image: exalink/conteo-backend:latest
    container_name: exalink-conteo-backend
    restart: unless-stopped
    environment:
      - TZ=UTC
    ports:
      - "${CONTEO_PORT:-2223}:8012"
    volumes:
      - ./backend/conteo/config:/app/config:rw
    networks:
      - lpr-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8012/health"]
      interval: 30s
      timeout: 5s
      retries: 3
    labels:
      - "com.exalink.service=conteo-backend"

  notificaciones-backend:
    build:
      context: ./backend/notificaciones
      dockerfile: Dockerfile
    image: exalink/notificaciones-backend:latest
    container_name: exalink-notificaciones-backend
    restart: unless-stopped
    environment:
      - TZ=UTC
    ports:
      - "${NOTIFICACIONES_PORT:-2224}:8022"
    volumes:
      - ./backend/notificaciones/config:/app/config:rw
    networks:
      - lpr-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8022/health"]
      interval: 30s
      timeout: 5s
      retries: 3
    labels:
      - "com.exalink.service=notificaciones-backend"

  frontend:
    build:
      context: ./frontend-build
      dockerfile_inline: |
        # syntax=docker/dockerfile:1
        FROM node:20-alpine AS base
        RUN apk add --no-cache libc6-compat python3 py3-pip build-base docker-cli
        WORKDIR /app
        COPY package.json package-lock.json* ./
        RUN npm ci
        COPY . .
        RUN npm run build
        FROM node:20-alpine AS runner
        WORKDIR /app
        ENV NODE_ENV production
        ENV NEXT_TELEMETRY_DISABLED 1
        RUN addgroup --system --gid 1001 nodejs
        RUN adduser --system --uid 1001 nextjs
        RUN mkdir .next
        RUN chown nextjs:nodejs .next
        RUN mkdir -p DB data
        RUN chown -R nextjs:nodejs DB data
        # Instalar dependencias de producci√≥n necesarias
        COPY package.json package-lock.json* ./
        RUN npm ci --only=production && npm cache clean --force
        COPY --from=0 --chown=nextjs:nodejs /app/.next/standalone/ ./
        RUN ls -la /app/server.js
        COPY --from=0 --chown=nextjs:nodejs /app/.next/static ./.next/static
        USER nextjs
        EXPOSE 3000
        ENV PORT 3000
        ENV HOSTNAME "0.0.0.0"
        CMD ["node", "server.js"]
    image: exalink/frontend:latest
    container_name: exalink-frontend
    restart: unless-stopped
    ports:
      - "${FRONTEND_PORT:-9002}:3000"
    environment:
      - NODE_ENV=production
      - NEXT_TELEMETRY_DISABLED=1
    volumes:
      - ./DB:/app/DB:rw
      - ./data:/app/data:rw
      - /var/run/docker.sock:/var/run/docker.sock:ro
    networks:
      - lpr-network
    depends_on:
      - lpr-backend
      - conteo-backend
      - notificaciones-backend
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    labels:
      - "com.exalink.service=frontend"

volumes:
  lpr-data:
    driver: local
    labels:
      - "com.exalink.volume=lpr-data"
  lpr-logs:
    driver: local
    labels:
      - "com.exalink.volume=lpr-logs"
  lpr-redis-data:
    driver: local
    labels:
      - "com.exalink.volume=lpr-redis-data"
  config-db:
    driver: local
    labels:
      - "com.exalink.volume=config-db"
  counting-db:
    driver: local
    labels:
      - "com.exalink.volume=counting-db"
  matriculas-db:
    driver: local
    labels:
      - "com.exalink.volume=matriculas-db"
  lpr-readings-db:
    driver: local
    labels:
      - "com.exalink.volume=lpr-readings-db"

networks:
  lpr-network:
    driver: bridge
    name: exalink-lpr-network
    labels:
      - "com.exalink.network=lpr-internal"
  public:
    driver: bridge
    name: exalink-public
    labels:
      com.exalink.network: public

